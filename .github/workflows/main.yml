name: Atualizar Dados FutStats

on:
  schedule:
    - cron: '*/10 * * * *' # Roda a cada 10 minutos para o "Ao Vivo"
  workflow_dispatch: 

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout do cÃ³digo
        uses: actions/checkout@v3

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar DependÃªncias
        run: |
          python -m pip install --upgrade pip
          pip install requests supabase groq requests-html beautifulsoup4 fake-useragent lxml_html_clean
          
      - name: ðŸ“¡ Executar Crawler Ao Vivo
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python crawler_ao_vivo.py

      - name: ðŸ“Š Executar Crawler de Tabelas e IA (Uma vez por hora)
        # Esta lÃ³gica faz o Crawler de tabelas e a IA rodarem apenas no minuto 0 de cada hora
        # Ex: 13:00 roda, 13:10 nÃ£o, 13:20 nÃ£o...
        if: github.event_name == 'workflow_dispatch' || contains(github.event.schedule, '0')
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          python crawler.py
          python analise_ia.py
