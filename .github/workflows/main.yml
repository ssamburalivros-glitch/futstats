name: Monitoramento FutStats

on:
  schedule:
    - cron: '*/5 * * * *'  # Rápido: Ao Vivo
    - cron: '0 */6 * * *'  # Lento: Calendário, Classificação e IA
  workflow_dispatch:

jobs:
  ao_vivo:
    if: github.event.schedule == '*/5 * * * *' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar Dependências
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 supabase
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Rodar Crawlers Rapidos
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          python crawler_ao_vivo.py
          python crawler_paulistao.py

      - name: Salvar Dados
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add games.json paulistao_data.json || echo "Arquivos json não encontrados"
          git commit -m "Update: Dados ao vivo e Paulistao" || echo "Sem mudanças para commitar"
          git push || echo "Erro ao dar push ou nada para subir"

  processamento_geral:
    if: github.event.schedule == '0 */6 * * *' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar Dependências e Playwright
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4 supabase playwright
          playwright install chromium # Necessário para o crawler de calendário clicar no site
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Rodar Crawlers e IA
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: |
          python crawler.py
          python crawler_details.py
          python crawler_forma.py
          python analise_ia.py
          python crawler_paulistao.py
          python crawler_calendario.py # NOVO: Roda o calendário robusto aqui

      - name: Salvar Tudo
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add .
          git commit -m "Update: Processamento 6h completo com Calendário" || echo "Sem mudanças para commitar"
          git push || echo "Erro ao dar push ou nada para subir"
