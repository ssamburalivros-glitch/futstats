name: Atualizar Dados FutStats

on:
  schedule:
    - cron: '*/2 * * * *' # Roda a cada 2 minutos
  workflow_dispatch: 

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout do cÃ³digo
        uses: actions/checkout@v3

      - name: Configurar Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Instalar DependÃªncias
        run: |
          python -m pip install --upgrade pip
          # Adicionei explicitamente as bibliotecas que faltavam no comando anterior
          pip install requests supabase groq requests-html beautifulsoup4 fake-useragent lxml_html_clean
          
      - name: ðŸ“¡ Executar Crawler Ao Vivo
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python crawler_ao_vivo.py

      - name: ðŸ“Š Executar Crawler de Tabelas
        # Corrigido para rodar no minuto 0 ou 30 de cada hora
        if: github.event_name == 'workflow_dispatch' || (github.event.schedule == '*/2 * * * *' && (github.event.minute == '0' || github.event.minute == '30'))
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python crawler.py

      - name: ðŸ¤– Gerar AnÃ¡lise com IA
        # Simplificado: Roda se for manual OU se o script detectar que deve rodar
        if: always() 
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
        run: python analise_ia.py
